{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d469cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 3.2595 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.2483 - accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.2370 - accuracy: 0.1429\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.2253 - accuracy: 0.1429\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.2132 - accuracy: 0.1429\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.2002 - accuracy: 0.1429\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3.1861 - accuracy: 0.1429\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.1708 - accuracy: 0.1429\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.1538 - accuracy: 0.1429\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.1349 - accuracy: 0.1429\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.1139 - accuracy: 0.1429\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.0903 - accuracy: 0.1429\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.0640 - accuracy: 0.1429\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.0347 - accuracy: 0.1429\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.0020 - accuracy: 0.1429\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.9660 - accuracy: 0.1429\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.9268 - accuracy: 0.1429\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.8847 - accuracy: 0.1429\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.8405 - accuracy: 0.1429\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.7954 - accuracy: 0.1429\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.7507 - accuracy: 0.1429\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.7069 - accuracy: 0.1429\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.6629 - accuracy: 0.1429\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.6157 - accuracy: 0.1905\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.5627 - accuracy: 0.1905\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5031 - accuracy: 0.1905\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 2.4375 - accuracy: 0.2381\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3669 - accuracy: 0.3333\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.2914 - accuracy: 0.3810\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.2108 - accuracy: 0.4762\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.1258 - accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.0377 - accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.9478 - accuracy: 0.6190\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.8569 - accuracy: 0.6190\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7646 - accuracy: 0.6667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.6717 - accuracy: 0.7143\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.5800 - accuracy: 0.7143\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4915 - accuracy: 0.7143\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4062 - accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3228 - accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2403 - accuracy: 0.8095\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1589 - accuracy: 0.8571\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.0793 - accuracy: 0.9524\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0027 - accuracy: 0.9524\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9302 - accuracy: 0.9524\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8618 - accuracy: 0.9524\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7964 - accuracy: 0.9524\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7335 - accuracy: 0.9524\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6731 - accuracy: 0.9524\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6156 - accuracy: 0.9524\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5614 - accuracy: 0.9524\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5100 - accuracy: 0.9524\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4617 - accuracy: 0.9524\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4178 - accuracy: 0.9524\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3786 - accuracy: 0.9524\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3440 - accuracy: 0.9524\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3128 - accuracy: 0.9524\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2845 - accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2590 - accuracy: 0.9524\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2367 - accuracy: 0.9524\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2174 - accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2009 - accuracy: 0.9524\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1866 - accuracy: 0.9524\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1742 - accuracy: 0.9524\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1633 - accuracy: 0.9524\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1536 - accuracy: 0.9524\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1451 - accuracy: 0.9524\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1376 - accuracy: 0.9524\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1309 - accuracy: 0.9524\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1251 - accuracy: 0.9524\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1199 - accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1154 - accuracy: 0.9524\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1114 - accuracy: 0.9524\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1079 - accuracy: 0.9524\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1047 - accuracy: 0.9524\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1019 - accuracy: 0.9524\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0994 - accuracy: 0.9524\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0971 - accuracy: 0.9524\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0951 - accuracy: 0.9524\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0932 - accuracy: 0.9524\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0915 - accuracy: 0.9524\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0900 - accuracy: 0.9524\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0887 - accuracy: 0.9524\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0874 - accuracy: 0.9524\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0863 - accuracy: 0.9524\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0853 - accuracy: 0.9524\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0844 - accuracy: 0.9524\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0836 - accuracy: 0.9524\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0828 - accuracy: 0.9524\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0822 - accuracy: 0.9524\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0815 - accuracy: 0.9524\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0809 - accuracy: 0.9524\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0804 - accuracy: 0.9524\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0799 - accuracy: 0.9524\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0794 - accuracy: 0.9524\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0790 - accuracy: 0.9524\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0785 - accuracy: 0.9524\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0782 - accuracy: 0.9524\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0778 - accuracy: 0.9524\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0775 - accuracy: 0.9524\n",
      "Hi there there well thank you\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example dataset\n",
    "conversations = [\n",
    "    \"Hi there!\",\n",
    "    \"Hello!\",\n",
    "    \"How are you?\",\n",
    "    \"I'm doing well, thank you.\",\n",
    "    \"That's great to hear!\",\n",
    "    \"Yes, it is. How about you?\",\n",
    "    \"I'm good too. Thanks for asking.\",\n",
    "    \"You're welcome.\"\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(conversations)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences and labels\n",
    "input_sequences = []\n",
    "for line in conversations:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and labels\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
    "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(xs, ys, epochs=100, verbose=1)\n",
    "\n",
    "# Function to generate response\n",
    "def generate_response(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Test the chatbot\n",
    "print(generate_response(\"Hi\", 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8ed17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me what is AI? are you thank you you\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(\"Tell me what is AI?\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974d0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4bb2ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "898/898 [==============================] - 55s 55ms/step - loss: 2.3477 - accuracy: 0.4847\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 51s 57ms/step - loss: 0.3404 - accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 51s 57ms/step - loss: 0.2590 - accuracy: 0.9043\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 51s 57ms/step - loss: 0.2348 - accuracy: 0.9062\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 52s 57ms/step - loss: 0.2327 - accuracy: 0.9047\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 51s 57ms/step - loss: 0.2254 - accuracy: 0.9054\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 52s 57ms/step - loss: 0.2315 - accuracy: 0.9023\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 51s 57ms/step - loss: 0.2301 - accuracy: 0.9042\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 52s 58ms/step - loss: 0.2217 - accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 52s 57ms/step - loss: 0.2205 - accuracy: 0.9052\n",
      "Hi i'd like to inquire about\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load data from text file\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = file.readlines()\n",
    "    return data\n",
    "\n",
    "# Example: Load data from your .txt file\n",
    "file_path = 'customer_experience_dataset.txt'\n",
    "conversations = load_data(file_path)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(conversations)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences and labels\n",
    "input_sequences = []\n",
    "for line in conversations:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and labels\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
    "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(xs, ys, epochs=10, verbose=1)\n",
    "\n",
    "# Function to generate response\n",
    "def generate_response(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Test the chatbot\n",
    "print(generate_response(\"Hi\", 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d2c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the requirements for applying for a mortgage? you'll need to provide detailed information about\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(\"What are the requirements for applying for a mortgage?\", 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb5f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "499b3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from tkinter import messagebox\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate response\n",
    "def generate_response(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Function to handle user input and display response\n",
    "def send():\n",
    "    user_input = entry.get()\n",
    "    entry.delete(0, tk.END)\n",
    "    if user_input.strip() != \"\":\n",
    "        response = generate_response(user_input, 10)\n",
    "        chat_history.config(state=tk.NORMAL)\n",
    "        chat_history.insert(tk.END, \"You: \" + user_input + \"\\n\", 'user')\n",
    "        chat_history.insert(tk.END, \"Bot: \" + response + \"\\n\", 'bot')\n",
    "        chat_history.config(state=tk.DISABLED)\n",
    "        chat_history.see(tk.END)\n",
    "\n",
    "# Create main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Chatbot\")\n",
    "\n",
    "# Create chat history window\n",
    "chat_history = scrolledtext.ScrolledText(root, width=50, height=20)\n",
    "chat_history.grid(row=0, column=0, padx=10, pady=10, sticky=\"nsew\")\n",
    "chat_history.tag_configure('user', foreground='blue')\n",
    "chat_history.tag_configure('bot', foreground='red')\n",
    "chat_history.config(state=tk.DISABLED)\n",
    "\n",
    "# Create input entry field\n",
    "entry = tk.Entry(root, width=40)\n",
    "entry.grid(row=1, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "# Create send button\n",
    "send_button = tk.Button(root, text=\"Send\", command=send)\n",
    "send_button.grid(row=1, column=1, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "# Function to handle closing the window\n",
    "def on_closing():\n",
    "    if messagebox.askokcancel(\"Quit\", \"Do you want to quit?\"):\n",
    "        root.destroy()\n",
    "\n",
    "root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "# Run the main event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b9c23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bdc4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "388ad3ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 8s 8s/step - loss: 2.5979 - val_loss: 2.6095\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 2.4338 - val_loss: 2.6468\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 2.2821 - val_loss: 2.7319\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.1425 - val_loss: 2.8801\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 2.0175 - val_loss: 3.0921\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 1.9104 - val_loss: 3.3405\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.8186 - val_loss: 3.5794\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.7298 - val_loss: 3.7808\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.6323 - val_loss: 3.9541\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.5274 - val_loss: 4.1375\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.4297 - val_loss: 4.3746\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.3543 - val_loss: 4.6675\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.2935 - val_loss: 4.9663\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 1.2203 - val_loss: 5.2461\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.1316 - val_loss: 5.5220\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0502 - val_loss: 5.7985\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9846 - val_loss: 6.0536\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9146 - val_loss: 6.2889\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8334 - val_loss: 6.5390\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7629 - val_loss: 6.8102\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7053 - val_loss: 7.0557\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6326 - val_loss: 7.2782\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5584 - val_loss: 7.5080\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5004 - val_loss: 7.7460\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4431 - val_loss: 7.9844\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3834 - val_loss: 8.2073\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3341 - val_loss: 8.3912\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2894 - val_loss: 8.5384\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2439 - val_loss: 8.6790\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2094 - val_loss: 8.8363\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1817 - val_loss: 9.0194\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1548 - val_loss: 9.2109\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1334 - val_loss: 9.3755\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1170 - val_loss: 9.4941\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1011 - val_loss: 9.5738\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0883 - val_loss: 9.6412\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0793 - val_loss: 9.7251\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0706 - val_loss: 9.8327\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0624 - val_loss: 9.9499\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0561 - val_loss: 10.0566\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0508 - val_loss: 10.1392\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0454 - val_loss: 10.1986\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0409 - val_loss: 10.2503\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0374 - val_loss: 10.3125\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0342 - val_loss: 10.3904\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0309 - val_loss: 10.4742\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0281 - val_loss: 10.5473\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0259 - val_loss: 10.5979\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0240 - val_loss: 10.6252\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0222 - val_loss: 10.6399\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0205 - val_loss: 10.6573\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0191 - val_loss: 10.6903\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0178 - val_loss: 10.7442\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0166 - val_loss: 10.8158\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0155 - val_loss: 10.8951\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0145 - val_loss: 10.9701\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0137 - val_loss: 11.0312\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0130 - val_loss: 11.0741\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0123 - val_loss: 11.1003\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0117 - val_loss: 11.1148\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0111 - val_loss: 11.1247\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0106 - val_loss: 11.1367\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0101 - val_loss: 11.1552\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0097 - val_loss: 11.1817\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0093 - val_loss: 11.2150\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0089 - val_loss: 11.2517\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0085 - val_loss: 11.2881\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0082 - val_loss: 11.3209\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0079 - val_loss: 11.3480\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0076 - val_loss: 11.3687\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0074 - val_loss: 11.3841\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0071 - val_loss: 11.3958\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0069 - val_loss: 11.4062\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0067 - val_loss: 11.4177\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0065 - val_loss: 11.4320\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0063 - val_loss: 11.4501\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0061 - val_loss: 11.4719\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0059 - val_loss: 11.4965\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0058 - val_loss: 11.5221\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0056 - val_loss: 11.5473\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0055 - val_loss: 11.5703\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0054 - val_loss: 11.5900\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0052 - val_loss: 11.6059\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0051 - val_loss: 11.6180\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0050 - val_loss: 11.6270\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0049 - val_loss: 11.6338\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0048 - val_loss: 11.6396\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0047 - val_loss: 11.6456\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0046 - val_loss: 11.6529\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0045 - val_loss: 11.6621\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0044 - val_loss: 11.6737\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0043 - val_loss: 11.6875\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0042 - val_loss: 11.7031\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0042 - val_loss: 11.7199\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0041 - val_loss: 11.7371\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0040 - val_loss: 11.7541\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0040 - val_loss: 11.7701\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - val_loss: 11.7849\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - val_loss: 11.7982\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0038 - val_loss: 11.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efddce0130>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Reshape\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example dataset (replace with your own dataset)\n",
    "input_texts = ['What is your name?', 'How old are you?', 'Where do you live?']\n",
    "target_texts = ['My name is John.', 'I am 25 years old.', 'I live in New York.']\n",
    "\n",
    "# Tokenize input and output texts\n",
    "tokenizer_input = Tokenizer()\n",
    "tokenizer_input.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_input.texts_to_sequences(input_texts)\n",
    "\n",
    "tokenizer_target = Tokenizer()\n",
    "tokenizer_target.fit_on_texts(target_texts)\n",
    "target_sequences = tokenizer_target.texts_to_sequences(target_texts)\n",
    "\n",
    "# Pad sequences to make them of same length\n",
    "max_input_len = max(len(seq) for seq in input_sequences)\n",
    "max_target_len = max(len(seq) for seq in target_sequences)\n",
    "\n",
    "encoder_input_data = pad_sequences(input_sequences, maxlen=max_input_len, padding='post')\n",
    "decoder_input_data = pad_sequences(target_sequences, maxlen=max_target_len, padding='post')\n",
    "\n",
    "# Prepare decoder target data (shifted by one timestep)\n",
    "decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "decoder_target_data[:, 0:-1] = decoder_input_data[:, 1:]\n",
    "\n",
    "# Define model\n",
    "latent_dim = 256  # Dimensionality of the encoding space\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_reshaped = Reshape((-1, 1))(encoder_inputs)  # Reshape input\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_reshaped)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_reshaped = Reshape((-1, 1))(decoder_inputs)  # Reshape input\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_reshaped, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(tokenizer_target.word_index) + 1, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=64,\n",
    "          epochs=100,\n",
    "          validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5709837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393139ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e672afb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 18s 18s/step - loss: 3.9528 - val_loss: 3.9525\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.9286 - val_loss: 3.9543\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.9033 - val_loss: 3.9562\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.8754 - val_loss: 3.9584\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.8429 - val_loss: 3.9610\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 3.8034 - val_loss: 3.9642\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.7537 - val_loss: 3.9686\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.6887 - val_loss: 3.9749\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 3.6014 - val_loss: 3.9849\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.4806 - val_loss: 4.0043\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.3123 - val_loss: 4.0613\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 3.0923 - val_loss: 4.3227\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 2.8664 - val_loss: 5.1602\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 2.7265 - val_loss: 6.0842\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 2.6225 - val_loss: 6.6904\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.4556 - val_loss: 7.1028\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 2.2565 - val_loss: 7.4363\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 2.0951 - val_loss: 7.7625\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.9801 - val_loss: 8.1001\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.8769 - val_loss: 8.4386\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7724 - val_loss: 8.7537\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.6695 - val_loss: 9.0599\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5672 - val_loss: 9.3815\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 1.4700 - val_loss: 9.7342\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.3889 - val_loss: 10.0544\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.3100 - val_loss: 10.3595\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.2474 - val_loss: 10.6401\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.1998 - val_loss: 10.8916\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1493 - val_loss: 11.0935\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0862 - val_loss: 11.2355\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0257 - val_loss: 11.3218\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.9683 - val_loss: 11.3618\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.9208 - val_loss: 11.3578\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8857 - val_loss: 11.3787\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.8469 - val_loss: 11.4948\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.8068 - val_loss: 11.6560\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7664 - val_loss: 11.7716\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7274 - val_loss: 11.8532\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6971 - val_loss: 11.9034\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6666 - val_loss: 11.9437\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6386 - val_loss: 11.9954\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.6077 - val_loss: 12.0610\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.5765 - val_loss: 12.1424\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.5510 - val_loss: 12.2598\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5256 - val_loss: 12.3961\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5049 - val_loss: 12.5007\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4796 - val_loss: 12.6000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4572 - val_loss: 12.6968\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4346 - val_loss: 12.7874\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4159 - val_loss: 12.8875\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 9) for input KerasTensor(type_spec=TensorSpec(shape=(None, 9), dtype=tf.float32, name='input_47'), name='input_47', description=\"created by layer 'input_47'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Response: we track your order by logging into your account.  we\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Sample dataset\n",
    "customer_queries = [\n",
    "    \"How can I track my order?\",\n",
    "    \"What is your return policy?\",\n",
    "    \"Do you offer free shipping?\",\n",
    "    \"I received a damaged item, what should I do?\"\n",
    "]\n",
    "company_responses = [\n",
    "    \"You can track your order by logging into your account.\",\n",
    "    \"Our return policy allows returns within 30 days of purchase.\",\n",
    "    \"Yes, we offer free shipping on orders over $50.\",\n",
    "    \"Please contact our customer support for assistance with damaged items.\"\n",
    "]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(customer_queries + company_responses)\n",
    "\n",
    "# Define hyperparameters\n",
    "max_sequence_length = max([len(seq.split()) for seq in customer_queries])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Generate sequences\n",
    "encoder_sequences = tokenizer.texts_to_sequences(customer_queries)\n",
    "decoder_sequences = tokenizer.texts_to_sequences(company_responses)\n",
    "\n",
    "# Pad sequences\n",
    "encoder_input_data = pad_sequences(encoder_sequences, maxlen=max_sequence_length, padding='post')\n",
    "decoder_input_data = pad_sequences(decoder_sequences, maxlen=max_sequence_length, padding='post')\n",
    "decoder_target_data = np.zeros(decoder_input_data.shape)\n",
    "\n",
    "for i in range(len(decoder_input_data)):\n",
    "    decoder_target_data[i, :-1] = decoder_input_data[i, 1:]\n",
    "    \n",
    "# Define model\n",
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "encoder_embedding = Embedding(vocab_size, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "decoder_embedding = Embedding(vocab_size, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Compile model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train model\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Define inference models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_embedding, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Define function to decode sequence\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer.index_word.get(sampled_token_index, '')\n",
    "        if sampled_word == '<end>' or len(decoded_sentence.split()) > max_sequence_length:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# Example usage\n",
    "input_seq = pad_sequences(tokenizer.texts_to_sequences([\"How can I track my order?\"]), maxlen=max_sequence_length, padding='post')\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Response:', decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5a3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776660e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51a6f2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 21s 567ms/step - loss: 4.7421 - val_loss: 4.1724\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 3.9205 - val_loss: 3.6283\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 3.4798 - val_loss: 3.2253\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 3s 204ms/step - loss: 3.0326 - val_loss: 2.7104\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 2.4883 - val_loss: 2.1313\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 1.9022 - val_loss: 1.5767\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 1.3643 - val_loss: 1.0909\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.9293 - val_loss: 0.7362\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.6258 - val_loss: 0.4938\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.4216 - val_loss: 0.3361\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.2897 - val_loss: 0.2332\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.2042 - val_loss: 0.1677\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.1489 - val_loss: 0.1248\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.1125 - val_loss: 0.0961\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 0.0879 - val_loss: 0.0761\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0704 - val_loss: 0.0617\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.0578 - val_loss: 0.0513\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.0484 - val_loss: 0.0435\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0413 - val_loss: 0.0374\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0357 - val_loss: 0.0326\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 3s 225ms/step - loss: 0.0313 - val_loss: 0.0287\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 3s 238ms/step - loss: 0.0277 - val_loss: 0.0255\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0247 - val_loss: 0.0229\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0222 - val_loss: 0.0207\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0201 - val_loss: 0.0188\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 3s 232ms/step - loss: 0.0183 - val_loss: 0.0172\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0168 - val_loss: 0.0158\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.0154 - val_loss: 0.0145\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.0143 - val_loss: 0.0135\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0132 - val_loss: 0.0125\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0123 - val_loss: 0.0117\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 3s 259ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 3s 225ms/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.0095 - val_loss: 0.0091\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0085 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0080 - val_loss: 0.0077\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.0076 - val_loss: 0.0073\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 3s 251ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 3s 233ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 3s 228ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 3s 226ms/step - loss: 0.0057 - val_loss: 0.0055\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.0055 - val_loss: 0.0053\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 3s 228ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 18) for input KerasTensor(type_spec=TensorSpec(shape=(None, 18), dtype=tf.float32, name='input_51'), name='input_51', description=\"created by layer 'input_51'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Response: and than you have available in your account. i can provide you with more information if you'd like.  and\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load dataset\n",
    "with open(\"customer_experience_dataset.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    lines = file.read().split(\"\\n\")\n",
    "\n",
    "# Separate customer queries and bankbot responses\n",
    "customer_queries = []\n",
    "bankbot_responses = []\n",
    "for line in lines:\n",
    "    if line.startswith(\"Customer:\"):\n",
    "        customer_queries.append(line[len(\"Customer:\"):].strip())\n",
    "    elif line.startswith(\"BankBot:\"):\n",
    "        bankbot_responses.append(line[len(\"BankBot:\"):].strip())\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(customer_queries + bankbot_responses)\n",
    "\n",
    "# Define hyperparameters\n",
    "max_sequence_length = max([len(seq.split()) for seq in customer_queries])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Generate sequences\n",
    "encoder_sequences = tokenizer.texts_to_sequences(customer_queries)\n",
    "decoder_sequences = tokenizer.texts_to_sequences(bankbot_responses)\n",
    "\n",
    "# Pad sequences\n",
    "encoder_input_data = pad_sequences(encoder_sequences, maxlen=max_sequence_length, padding='post')\n",
    "decoder_input_data = pad_sequences(decoder_sequences, maxlen=max_sequence_length, padding='post')\n",
    "decoder_target_data = np.zeros(decoder_input_data.shape)\n",
    "\n",
    "for i in range(len(decoder_input_data)):\n",
    "    decoder_target_data[i, :-1] = decoder_input_data[i, 1:]\n",
    "\n",
    "# Define model\n",
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "encoder_embedding = Embedding(vocab_size, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "decoder_embedding = Embedding(vocab_size, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Compile model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train model\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=64, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Define inference models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_embedding, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Define function to decode sequence\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer.index_word.get(sampled_token_index, '')\n",
    "        if sampled_word == '<end>' or len(decoded_sentence.split()) > max_sequence_length:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# Example usage\n",
    "input_seq = pad_sequences(tokenizer.texts_to_sequences([\"Can you explain the overdraft fees on my account?\"]), maxlen=max_sequence_length, padding='post')\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Response:', decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d7b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "808bf3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Response: and offer special discounts and benefits for students. i can provide you with more information if you'd like.  and\n"
     ]
    }
   ],
   "source": [
    "input_seq = pad_sequences(tokenizer.texts_to_sequences([\"Do you offer any discounts for students?\"]),\n",
    "                          maxlen=max_sequence_length, padding='post')\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Response:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "657e1bbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Customer Service Chatbot!\n",
      "Type 'exit' to end the conversation.\n",
      "You: Hi\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "BankBot: and the of our can provide you with more information if you'd like.  and like.  and like.  and like.\n",
      "You: What is the process for opening a new checking account?\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "BankBot: and open a new checking account, you'll need to visit one of our branches with valid identification.  and like.\n",
      "You: exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def chat_with_bot():\n",
    "    print(\"Welcome to the Customer Service Chatbot!\")\n",
    "    print(\"Type 'exit' to end the conversation.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        input_seq = pad_sequences(tokenizer.texts_to_sequences([user_input]), maxlen=max_sequence_length, padding='post')\n",
    "        decoded_sentence = decode_sequence(input_seq)\n",
    "        print(\"BankBot:\", decoded_sentence)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_bot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1df576f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67c39174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "\n",
    "def send_message():\n",
    "    user_message = user_input.get()\n",
    "    chat_history.config(state=tk.NORMAL)\n",
    "    chat_history.insert(tk.END, \"You: \" + user_message + \"\\n\")\n",
    "    chat_history.config(state=tk.DISABLED)\n",
    "    user_input.delete(0, tk.END)\n",
    "    \n",
    "    input_seq = pad_sequences(tokenizer.texts_to_sequences([user_message]), maxlen=max_sequence_length, padding='post')\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    chat_history.config(state=tk.NORMAL)\n",
    "    chat_history.insert(tk.END, \"BankBot: \" + decoded_sentence + \"\\n\")\n",
    "    chat_history.config(state=tk.DISABLED)\n",
    "\n",
    "# Create main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Customer Service Chatbot\")\n",
    "\n",
    "# Create chat history display\n",
    "chat_history = scrolledtext.ScrolledText(window, wrap=tk.WORD, state=tk.DISABLED)\n",
    "chat_history.pack(expand=True, fill=tk.BOTH)\n",
    "\n",
    "# Create user input field\n",
    "user_input = tk.Entry(window, width=50)\n",
    "user_input.pack(pady=10)\n",
    "\n",
    "# Create send button\n",
    "send_button = tk.Button(window, text=\"Send\", command=send_message)\n",
    "send_button.pack()\n",
    "\n",
    "# Start the GUI event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c304f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62a63cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, INSERT\n",
    "\n",
    "def send_message():\n",
    "    user_message = user_input.get()\n",
    "    user_input.delete(0, tk.END)\n",
    "    \n",
    "    chat_history.config(state=tk.NORMAL)\n",
    "    chat_history.insert(tk.END, \"You: \" + user_message + \"\\n\", \"user_message\")\n",
    "    chat_history.insert(tk.END, \"BankBot: \" + \"Response from the bot\" + \"\\n\", \"bot_message\")\n",
    "    chat_history.insert(tk.END, \"\\n\")\n",
    "    chat_history.see(tk.END)\n",
    "    chat_history.config(state=tk.DISABLED)\n",
    "\n",
    "# Create main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Customer Service Chatbot\")\n",
    "window.geometry(\"500x400\")\n",
    "\n",
    "# Create chat history display\n",
    "chat_history = scrolledtext.ScrolledText(window, wrap=tk.WORD, state=tk.DISABLED)\n",
    "chat_history.tag_config(\"user_message\", foreground=\"blue\")\n",
    "chat_history.tag_config(\"bot_message\", foreground=\"green\")\n",
    "chat_history.pack(expand=True, fill=tk.BOTH)\n",
    "\n",
    "# Create user input field\n",
    "user_input = tk.Entry(window, width=50)\n",
    "user_input.pack(pady=10)\n",
    "\n",
    "# Create send button\n",
    "send_button = tk.Button(window, text=\"Send\", command=send_message)\n",
    "send_button.pack()\n",
    "\n",
    "# Start the GUI event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d38fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b0762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43a9dc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid date: 2022-03-30\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def validate_and_extract_date(date_string):\n",
    "    try:\n",
    "        # Parse the date string\n",
    "        date_obj = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S %Z')\n",
    "        \n",
    "        # Extract only the date part\n",
    "        extracted_date = date_obj.date()\n",
    "        \n",
    "        # Return the extracted date\n",
    "        return extracted_date, True\n",
    "    except ValueError:\n",
    "        # If parsing fails, return None for date and False for validation\n",
    "        return None, False\n",
    "\n",
    "# Example usage\n",
    "date_string = \"2022-3-30 06:01:22 GMT\"\n",
    "extracted_date, is_valid = validate_and_extract_date(date_string)\n",
    "\n",
    "if is_valid:\n",
    "    print(\"Valid date:\", extracted_date)\n",
    "else:\n",
    "    print(\"Invalid date format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f459c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid date: 2022-04-30\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def validate_and_extract_date(date_string):\n",
    "    try:\n",
    "        # Parse the date string\n",
    "        date_obj = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S %Z')\n",
    "        \n",
    "        # Extract only the date part and convert it to string format\n",
    "        extracted_date = date_obj.date().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Return the extracted date\n",
    "        return extracted_date, True\n",
    "    except ValueError:\n",
    "        # If parsing fails, return None for date and False for validation\n",
    "        return None, False\n",
    "\n",
    "# Example usage\n",
    "date_string = \"2022-04-30 06:01:22 UTC\"\n",
    "extracted_date, is_valid = validate_and_extract_date(date_string)\n",
    "\n",
    "if is_valid:\n",
    "    print(\"Valid date:\", extracted_date)\n",
    "else:\n",
    "    print(\"Invalid date format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3490dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "840db031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid date: 2022-04-30\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def validate_and_extract_date(date_string):\n",
    "    date_formats = [\n",
    "        '%Y-%m-%d %H:%M:%S %Z',   # Example: 2022-04-30 06:01:22 UTC\n",
    "        '%Y-%m-%d %H:%M:%S',       # Example: 2022-04-30 06:01:22\n",
    "        '%Y-%m-%d',                # Example: 2022-04-30\n",
    "        '%m/%d/%Y %H:%M:%S %Z',    # Example: 04/30/2022 06:01:22 UTC\n",
    "        '%m/%d/%Y %H:%M:%S',       # Example: 04/30/2022 06:01:22\n",
    "        '%m/%d/%Y',                # Example: 04/30/2022\n",
    "        '%m-%d-%Y %H:%M:%S %Z',    # Example: 04-30-2022 06:01:22 UTC\n",
    "        '%m-%d-%Y %H:%M:%S',       # Example: 04-30-2022 06:01:22\n",
    "        '%m-%d-%Y',                # Example: 04-30-2022\n",
    "        '%Y/%m/%d %H:%M:%S %Z',    # Example: 2022/04/30 06:01:22 UTC\n",
    "        '%Y/%m/%d'\n",
    "    ]\n",
    "    \n",
    "    for format_str in date_formats:\n",
    "        try:\n",
    "            # Parse the date string\n",
    "            date_obj = datetime.strptime(date_string, format_str)\n",
    "            \n",
    "            # Extract only the date part and convert it to string format\n",
    "            extracted_date = date_obj.date().strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Return the extracted date and True for validation\n",
    "            return extracted_date, True\n",
    "        except ValueError:\n",
    "            continue  # Try the next format if parsing fails\n",
    "\n",
    "    # If parsing fails for all formats, return None for the date and False for validation\n",
    "    return None, False\n",
    "\n",
    "# Example usage\n",
    "date_string = '04/30/2022 06:01:22 UTC'\n",
    "extracted_date, is_valid = validate_and_extract_date(date_string)\n",
    "\n",
    "if is_valid:\n",
    "    print(\"Valid date:\", extracted_date)\n",
    "else:\n",
    "    print(\"Invalid date format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174c4836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4745cf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid date: 04-30-2022\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def validate_and_extract_date(date_string):\n",
    "    date_formats = [\n",
    "        '%Y-%m-%d %H:%M:%S %Z',   # Example: 2022-04-30 06:01:22 UTC\n",
    "        '%Y-%m-%d %H:%M:%S',       # Example: 2022-04-30 06:01:22\n",
    "        '%Y-%m-%d',                # Example: 2022-04-30\n",
    "        '%m/%d/%Y %H:%M:%S %Z',    # Example: 04/30/2022 06:01:22 UTC\n",
    "        '%m/%d/%Y %H:%M:%S',       # Example: 04/30/2022 06:01:22\n",
    "        '%m/%d/%Y',                # Example: 04/30/2022\n",
    "        '%m-%d-%Y %H:%M:%S %Z',    # Example: 04-30-2022 06:01:22 UTC\n",
    "        '%m-%d-%Y %H:%M:%S',       # Example: 04-30-2022 06:01:22\n",
    "        '%m-%d-%Y',                # Example: 04-30-2022\n",
    "        '%Y/%m/%d %H:%M:%S %Z',    # Example: 2022/04/30 06:01:22 UTC\n",
    "    ]\n",
    "    \n",
    "    for format_str in date_formats:\n",
    "        try:\n",
    "            # Parse the date string\n",
    "            date_obj = datetime.strptime(date_string, format_str)\n",
    "            \n",
    "            # Extract only the date part and convert it to string format\n",
    "            extracted_date = date_obj.date().strftime(format_str.split(' ')[0].replace('/', '-'))\n",
    "            \n",
    "            # Return the extracted date and True for validation\n",
    "            return extracted_date, True\n",
    "        except ValueError:\n",
    "            continue  # Try the next format if parsing fails\n",
    "\n",
    "    # If parsing fails for all formats, return None for the date and False for validation\n",
    "    return None, False\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Example usage\n",
    "date_string = '04-30-2022 06:01:22 UTC'\n",
    "extracted_date, is_valid = validate_and_extract_date(date_string)\n",
    "\n",
    "if is_valid:\n",
    "    print(\"Valid date:\", extracted_date)\n",
    "else:\n",
    "    print(\"Invalid date format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843d8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d4fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
