{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00035354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43340565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "fraud_rate = 0.02\n",
    "\n",
    "categories = ['A', 'B', 'C']\n",
    "merchant_names = ['X', 'Y', 'Z']\n",
    "\n",
    "category_data = np.random.choice(categories, size=n_records)\n",
    "merchant_name_data = np.random.choice(merchant_names, size=n_records)\n",
    "\n",
    "amount = np.random.normal(loc=100, scale=50, size=n_records)\n",
    "amount_last_30_days = np.random.normal(loc=50, scale=25, size=n_records)\n",
    "count_last_30_days = np.random.poisson(lam=3, size=n_records)\n",
    "address_change_last_30_days = np.random.choice([0, 1], size=n_records)\n",
    "phone_change_last_60_days = np.random.choice([0, 1], size=n_records)\n",
    "\n",
    "# Generate fraud labels\n",
    "is_fraud = np.random.choice([0, 1], size=n_records, p=[1 - fraud_rate, fraud_rate])\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'category': category_data,\n",
    "    'merchant_name': merchant_name_data,\n",
    "    'amount': amount,\n",
    "    'amount_last_30_days': amount_last_30_days,\n",
    "    'count_last_30_days': count_last_30_days,\n",
    "    'address_change_last_30_days': address_change_last_30_days,\n",
    "    'phone_change_last_60_days': phone_change_last_60_days,\n",
    "    'target': is_fraud\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3481e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>merchant_name</th>\n",
       "      <th>amount</th>\n",
       "      <th>amount_last_30_days</th>\n",
       "      <th>count_last_30_days</th>\n",
       "      <th>address_change_last_30_days</th>\n",
       "      <th>phone_change_last_60_days</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>Z</td>\n",
       "      <td>183.576012</td>\n",
       "      <td>87.030964</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Z</td>\n",
       "      <td>89.798471</td>\n",
       "      <td>38.035564</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Z</td>\n",
       "      <td>90.697175</td>\n",
       "      <td>64.951442</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>Z</td>\n",
       "      <td>152.138259</td>\n",
       "      <td>28.765327</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "      <td>125.299555</td>\n",
       "      <td>46.580418</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category merchant_name      amount  amount_last_30_days  count_last_30_days  \\\n",
       "0        C             Z  183.576012            87.030964                   3   \n",
       "1        A             Z   89.798471            38.035564                   3   \n",
       "2        C             Z   90.697175            64.951442                   2   \n",
       "3        C             Z  152.138259            28.765327                   2   \n",
       "4        A             X  125.299555            46.580418                   3   \n",
       "\n",
       "   address_change_last_30_days  phone_change_last_60_days  target  \n",
       "0                            1                          0       0  \n",
       "1                            1                          1       0  \n",
       "2                            0                          1       0  \n",
       "3                            0                          0       0  \n",
       "4                            0                          1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23543ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    980\n",
       "1     20\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0ee6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_woe(df, cat_var, target_var):\n",
    "    # Calculate the percentage of events and non-events for each category\n",
    "    event_perc = df.groupby(cat_var)[target_var].mean()\n",
    "    non_event_perc = 1 - event_perc\n",
    "\n",
    "    # Calculate the WoE for each category\n",
    "    woe = np.log((non_event_perc + 0.5) / (event_perc + 0.5))\n",
    "\n",
    "    return woe\n",
    "\n",
    "def calculate_adj_woe(df, cat_var, target_var):\n",
    "    woe = calculate_woe(df, cat_var, target_var)\n",
    "    n_event = df[target_var].sum()\n",
    "    n_non_event = df.shape[0] - n_event\n",
    "    adj_woe = woe * (np.log(n_non_event / n_event))\n",
    "\n",
    "    return adj_woe\n",
    "\n",
    "def calculate_smoothed_woe(df, cat_var, target_var, smooth_factor=10):\n",
    "    # Calculate the percentage of events and non-events for each category\n",
    "    event_perc = df.groupby(cat_var)[target_var].mean()\n",
    "    non_event_perc = 1 - event_perc\n",
    "\n",
    "    # Calculate smoothed WoE for each category\n",
    "    smoothed_woe = np.log(((non_event_perc * (1 - smooth_factor)) + (event_perc * smooth_factor)) / \\\n",
    "                          ((event_perc * (1 - smooth_factor)) + (non_event_perc * smooth_factor)))\n",
    "\n",
    "    return smoothed_woe\n",
    "\n",
    "def calculate_iv(df, cat_var, target_var):\n",
    "    event_perc = df.groupby(cat_var)[target_var].mean()\n",
    "    non_event_perc = 1 - event_perc\n",
    "    event_rate = df[target_var].mean()\n",
    "    iv = ((non_event_perc - event_perc) * np.log(non_event_perc / event_perc)).sum()\n",
    "    return iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3650cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Value (IV) for 'category': 11.533866431176268\n",
      "Information Value (IV) for 'merchant_name': 11.626707238843771\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Train a random forest model with WoE variables\u001b[39;00m\n\u001b[0;32m     39\u001b[0m rf_model_with_woe \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[43mrf_model_with_woe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_with_woe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     43\u001b[0m y_pred_rf_with_woe \u001b[38;5;241m=\u001b[39m rf_model_with_woe\u001b[38;5;241m.\u001b[39mpredict(X_test_with_woe)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Calculate WoE for 'category' and 'merchant_name'\n",
    "df['category_woe'] = calculate_woe(df, 'category', 'target')\n",
    "df['merchant_name_woe'] = calculate_woe(df, 'merchant_name', 'target')\n",
    "\n",
    "# Calculate Adj-WoE for 'category' and 'merchant_name'\n",
    "df['category_adj_woe'] = calculate_adj_woe(df, 'category', 'target')\n",
    "df['merchant_name_adj_woe'] = calculate_adj_woe(df, 'merchant_name', 'target')\n",
    "\n",
    "# Calculate Smoothed-WoE for 'category' and 'merchant_name'\n",
    "df['category_smoothed_woe'] = calculate_smoothed_woe(df, 'category', 'target')\n",
    "df['merchant_name_smoothed_woe'] = calculate_smoothed_woe(df, 'merchant_name', 'target')\n",
    "\n",
    "# Calculate IV for 'category' and 'merchant_name'\n",
    "iv_category = calculate_iv(df, 'category', 'target')\n",
    "iv_merchant_name = calculate_iv(df, 'merchant_name', 'target')\n",
    "\n",
    "print(\"Information Value (IV) for 'category':\", iv_category)\n",
    "print(\"Information Value (IV) for 'merchant_name':\", iv_merchant_name)\n",
    "\n",
    "# Define features and target variable\n",
    "features_with_woe = ['amount', 'amount_last_30_days', 'count_last_30_days',\n",
    "                     'address_change_last_30_days', 'phone_change_last_60_days',\n",
    "                     'category_woe', 'merchant_name_woe']\n",
    "\n",
    "features_without_woe = ['amount', 'amount_last_30_days', 'count_last_30_days',\n",
    "                        'address_change_last_30_days', 'phone_change_last_60_days']\n",
    "\n",
    "target = 'target'\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_with_woe = df[features_with_woe]\n",
    "y = df[target]\n",
    "X_train_with_woe, X_test_with_woe, y_train, y_test = train_test_split(X_with_woe, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_without_woe = df[features_without_woe]\n",
    "X_train_without_woe, X_test_without_woe = train_test_split(X_without_woe, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest model with WoE variables\n",
    "rf_model_with_woe = RandomForestClassifier(random_state=42)\n",
    "rf_model_with_woe.fit(X_train_with_woe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_with_woe = rf_model_with_woe.predict(X_test_with_woe)\n",
    "\n",
    "# Evaluate the model with WoE variables\n",
    "accuracy_rf_with_woe = accuracy_score(y_test, y_pred_rf_with_woe)\n",
    "print(\"\\nAccuracy with WoE variables (Random Forest):\", accuracy_rf_with_woe)\n",
    "print(\"Classification Report with WoE variables (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf_with_woe))\n",
    "\n",
    "# Get feature importance for the model with WoE variables\n",
    "importance_rf_with_woe = rf_model_with_woe.feature_importances_\n",
    "feature_importance_rf_with_woe = pd.DataFrame({'Feature': features_with_woe, 'Importance': importance_rf_with_woe})\n",
    "feature_importance_rf_with_woe_sorted = feature_importance_rf_with_woe.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance with WoE variables (Random Forest, sorted):\")\n",
    "print(feature_importance_rf_with_woe_sorted)\n",
    "\n",
    "# Train a random forest model without WoE variables\n",
    "rf_model_without_woe = RandomForestClassifier(random_state=42)\n",
    "rf_model_without_woe.fit(X_train_without_woe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_without_woe = rf_model_without_woe.predict(X_test_without_woe)\n",
    "\n",
    "# Evaluate the model without WoE variables\n",
    "accuracy_rf_without_woe = accuracy_score(y_test, y_pred_rf_without_woe)\n",
    "print(\"\\nAccuracy without WoE variables (Random Forest):\", accuracy_rf_without_woe)\n",
    "print(\"Classification Report without WoE variables (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf_without_woe))\n",
    "\n",
    "# Get feature importance for the model without WoE variables\n",
    "importance_rf_without_woe = rf_model_without_woe.feature_importances_\n",
    "feature_importance_rf_without_woe = pd.DataFrame({'Feature': features_without_woe, 'Importance': importance_rf_without_woe})\n",
    "feature_importance_rf_without_woe_sorted = feature_importance_rf_without_woe.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance without WoE variables (Random Forest, sorted):\")\n",
    "print(feature_importance_rf_without_woe_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b5d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7b3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6288d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with WoE variables (Random Forest): 0.99\n",
      "Classification Report with WoE variables (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       198\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.49      0.50      0.50       200\n",
      "weighted avg       0.98      0.99      0.99       200\n",
      "\n",
      "Error: The lengths of feature names and importances are not the same.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\pixel\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def calculate_woe(df, cat_var, target_var):\n",
    "    # Calculate the percentage of events and non-events for each category\n",
    "    event_perc = df.groupby(cat_var)[target_var].mean()\n",
    "    non_event_perc = 1 - event_perc\n",
    "\n",
    "    # Calculate the WoE for each category\n",
    "    woe = np.log((non_event_perc + 0.5) / (event_perc + 0.5))\n",
    "\n",
    "    return woe\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_records = 1000\n",
    "fraud_rate = 0.02\n",
    "\n",
    "categories = ['A', 'B', 'C']\n",
    "merchant_names = ['X', 'Y', 'Z']\n",
    "\n",
    "category_data = np.random.choice(categories, size=n_records)\n",
    "merchant_name_data = np.random.choice(merchant_names, size=n_records)\n",
    "\n",
    "amount = np.random.normal(loc=100, scale=50, size=n_records)\n",
    "amount_last_30_days = np.random.normal(loc=50, scale=25, size=n_records)\n",
    "count_last_30_days = np.random.poisson(lam=3, size=n_records)\n",
    "address_change_last_30_days = np.random.choice([0, 1], size=n_records)\n",
    "phone_change_last_60_days = np.random.choice([0, 1], size=n_records)\n",
    "\n",
    "# Generate fraud labels\n",
    "is_fraud = np.random.choice([0, 1], size=n_records, p=[1 - fraud_rate, fraud_rate])\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'category': category_data,\n",
    "    'merchant_name': merchant_name_data,\n",
    "    'amount': amount,\n",
    "    'amount_last_30_days': amount_last_30_days,\n",
    "    'count_last_30_days': count_last_30_days,\n",
    "    'address_change_last_30_days': address_change_last_30_days,\n",
    "    'phone_change_last_60_days': phone_change_last_60_days,\n",
    "    'target': is_fraud\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate WoE for 'category' and 'merchant_name'\n",
    "df['category_woe'] = calculate_woe(df, 'category', 'target')\n",
    "df['merchant_name_woe'] = calculate_woe(df, 'merchant_name', 'target')\n",
    "\n",
    "# Define features and target variable\n",
    "features_with_woe = ['amount', 'amount_last_30_days', 'count_last_30_days',\n",
    "                     'address_change_last_30_days', 'phone_change_last_60_days',\n",
    "                     'category_woe', 'merchant_name_woe']\n",
    "\n",
    "features_without_woe = ['amount', 'amount_last_30_days', 'count_last_30_days',\n",
    "                        'address_change_last_30_days', 'phone_change_last_60_days']\n",
    "\n",
    "target = 'target'\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_with_woe = df[features_with_woe]\n",
    "y = df[target]\n",
    "X_train_with_woe, X_test_with_woe, y_train, y_test = train_test_split(X_with_woe, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_without_woe = df[features_without_woe]\n",
    "X_train_without_woe, X_test_without_woe = train_test_split(X_without_woe, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handle missing values\n",
    "X_train_with_woe.fillna(X_train_with_woe.mean(), inplace=True)\n",
    "X_test_with_woe.fillna(X_test_with_woe.mean(), inplace=True)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_with_woe_imputed = imputer.fit_transform(X_train_with_woe)\n",
    "X_test_with_woe_imputed = imputer.transform(X_test_with_woe)\n",
    "\n",
    "# Train a random forest model with WoE variables\n",
    "rf_model_with_woe = RandomForestClassifier(random_state=42)\n",
    "rf_model_with_woe.fit(X_train_with_woe_imputed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_with_woe = rf_model_with_woe.predict(X_test_with_woe_imputed)\n",
    "\n",
    "# Evaluate the model with WoE variables\n",
    "accuracy_rf_with_woe = accuracy_score(y_test, y_pred_rf_with_woe)\n",
    "print(\"\\nAccuracy with WoE variables (Random Forest):\", accuracy_rf_with_woe)\n",
    "print(\"Classification Report with WoE variables (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf_with_woe))\n",
    "\n",
    "# Get feature importance for the model with WoE variables\n",
    "importance_rf_with_woe = rf_model_with_woe.feature_importances_\n",
    "\n",
    "# Ensure the lengths of feature names and importances are the same\n",
    "if len(features_with_woe) == len(importance_rf_with_woe):\n",
    "    feature_importance_rf_with_woe = pd.DataFrame({'Feature': features_with_woe, 'Importance': importance_rf_with_woe})\n",
    "    feature_importance_rf_with_woe_sorted = feature_importance_rf_with_woe.sort_values(by='Importance', ascending=False)\n",
    "    print(\"\\nFeature Importance with WoE variables (Random Forest, sorted):\")\n",
    "    print(feature_importance_rf_with_woe_sorted)\n",
    "else:\n",
    "    print(\"Error: The lengths of feature names and importances are not the same.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88f66698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_with_woe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db0e269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41333626, 0.45805978, 0.07557519, 0.02548112, 0.02754765])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_rf_with_woe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest model without WoE variables\n",
    "rf_model_without_woe = RandomForestClassifier(random_state=42)\n",
    "rf_model_without_woe.fit(X_train_without_woe, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf_without_woe = rf_model_without_woe.predict(X_test_without_woe)\n",
    "\n",
    "# Evaluate the model without WoE variables\n",
    "accuracy_rf_without_woe = accuracy_score(y_test, y_pred_rf_without_woe)\n",
    "print(\"\\nAccuracy without WoE variables (Random Forest):\", accuracy_rf_without_woe)\n",
    "print(\"Classification Report without WoE variables (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_rf_without_woe))\n",
    "\n",
    "# Get feature importance for the model without WoE variables\n",
    "importance_rf_without_woe = rf_model_without_woe.feature_importances_\n",
    "feature_importance_rf_without_woe = pd.DataFrame({'Feature': features_without_woe, 'Importance': importance_rf_without_woe})\n",
    "feature_importance_rf_without_woe_sorted = feature_importance_rf_without_woe.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importance without WoE variables (Random Forest, sorted):\")\n",
    "print(feature_importance_rf_without_woe_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5d0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934caffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e11269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3bf3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d29469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f48092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76799c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac62ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ebfd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef91654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d8c976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d1091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b2884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
